{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install -q transformers chromadb langchain-community google-api-python-client huggingface_hub sentence-transformers\n"
      ],
      "metadata": {
        "id": "_drIBRDyUTE8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8548da4-1e4a-4e30-e676-481171f56074"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m78.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m95.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.9/55.9 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.9/194.9 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.0/119.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.7/96.7 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 환경 설정\n",
        "HF_TOKEN = \"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\"  # Hugging Face 액세스 토큰\n",
        "GOOGLE_API_KEY = \"AIzaSyBQKWR0ude_nnBACdRGWnzGpI948vX4PuE\"  # Google Custom Search API 키\n",
        "GOOGLE_CSE_ID = \"3552b437aad314dcf\"  # Programmable Search Engine ID"
      ],
      "metadata": {
        "id": "xVo0GksFUUbQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1. 데이터 수집 및 벡터 저장소 구축 (NIH DSLD 사용)\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ],
      "metadata": {
        "id": "s5yJb_xMUVnm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NIH 식이보충제 라벨 데이터베이스에서 데이터 로드\n",
        "loader = WebBaseLoader([\"https://dsld.od.nih.gov/dsld/\"])\n",
        "documents = loader.load()"
      ],
      "metadata": {
        "id": "3shlTdrtUXBg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 문서 분할 (청크 크기 512, 50% 오버랩)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=512, chunk_overlap=256\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 임베딩 모델 초기화 (gte-base 사용)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n",
        "\n",
        "# ChromaDB에 벡터 저장\n",
        "vector_db = Chroma.from_documents(\n",
        "    texts, embeddings,\n",
        "    persist_directory=\"./chroma_db\",\n",
        "    collection_name=\"supplement_info\"\n",
        ")"
      ],
      "metadata": {
        "id": "Uw-n-TDgUYQL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. Google Programmable Search Engine 설정\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query, num=3):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
        "    res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, num=num).execute()\n",
        "    return [item[\"snippet\"] for item in res[\"items\"]]\n",
        "\n",
        "# 3. Gemma-3B 모델 초기화\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-3-1b-it\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "zVPaQJ5CUaYe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. 고급 프롬프트 엔지니어링 템플릿\n",
        "REACT_PROMPT = \"\"\"<start_of_turn>user\n",
        "사용자 정보:\n",
        "{user_info}\n",
        "\n",
        "현재 단계: {step}\n",
        "과거 관측: {history}\n",
        "\n",
        "다음 단계에서 수행해야 할 작업을 다음 형식 중 하나로 출력:\n",
        "1. 검색 필요: \"Action: search[검색어]\"\n",
        "2. DB 조회: \"Action: lookup[질문]\"\n",
        "3. 최종 답변: \"Final Answer: [답변]\"\n",
        "\n",
        "규칙:\n",
        "- 의학적 조언은 공인된 출처를 반드시 인용\n",
        "- 복용량 계산 시 사용자의 신체 조건 고려\n",
        "- 상호작용 가능성 경고<end_of_turn>\n",
        "<start_of_turn>assistant\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "xhiB8-ouUcFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. RAG 에이전트 실행 로직\n",
        "def run_agent(user_input, max_steps=5):\n",
        "    history = []\n",
        "    for step in range(max_steps):\n",
        "        # ReAct 프롬프트 구성\n",
        "        prompt = REACT_PROMPT.format(\n",
        "            user_info=user_input,\n",
        "            step=step+1,\n",
        "            history=\"\\n\".join(history[-3:])\n",
        "        )\n",
        "\n",
        "        # 모델 추론\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # 액션 파싱\n",
        "        if \"Final Answer:\" in response:\n",
        "            print(f\"\\nStep {step+1}: 최종 답변 생성\")\n",
        "            return response.split(\"Final Answer:\")[-1].strip()\n",
        "\n",
        "        # 액션 실행 및 관측 기록\n",
        "        action_type, query = parse_action(response)\n",
        "        observation = execute_action(action_type, query)\n",
        "\n",
        "        print(f\"\\nStep {step+1}:\")\n",
        "        print(f\"생각: {response.split('Action:')[0].strip()}\")\n",
        "        print(f\"액션: {action_type}({query})\")\n",
        "        print(f\"관측: {observation[:200]}...\")\n",
        "\n",
        "        history.append(f\"Step {step+1}: {observation[:200]}\")\n",
        "\n",
        "# 액션 처리 함수\n",
        "def parse_action(response):\n",
        "    action_line = response.split(\"Action:\")[-1].split(\"\\n\")[0].strip()\n",
        "    if \"search[\" in action_line:\n",
        "        return \"search\", action_line.split(\"[\")[1].split(\"]\")[0]\n",
        "    elif \"lookup[\" in action_line:\n",
        "        return \"lookup\", action_line.split(\"[\")[1].split(\"]\")[0]\n",
        "    return \"unknown\", \"\"\n",
        "\n",
        "def execute_action(action_type, query):\n",
        "    if action_type == \"search\":\n",
        "        return \"\\n\".join(google_search(query))\n",
        "    elif action_type == \"lookup\":\n",
        "        docs = vector_db.similarity_search(query, k=3)\n",
        "        return \"\\n\".join([d.page_content for d in docs])\n",
        "    return \"No action performed\"\n"
      ],
      "metadata": {
        "id": "CQ_TGCVHUdea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 실행 예시\n",
        "user_input = \"\"\"\n",
        "사용자 프로필:\n",
        "- 35세 임산부(6개월)\n",
        "- 현재 복용중: 프리네이트칼슘 500mg (1일 3회)\n",
        "- 최근 증상: 피로감 증가, 근육 경련\n",
        "- 선호사항: 해조류 성분 피해야 함\n",
        "\"\"\"\n",
        "\n",
        "result = run_agent(user_input)\n",
        "print(\"\\n최종 추천:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "id": "rBKUb8jRUeyG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}