{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_drIBRDyUTE8"
      },
      "outputs": [],
      "source": [
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "!pip install -q transformers chromadb langchain-community google-api-python-client huggingface_hub sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVo0GksFUUbQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Colab Secretsì—ì„œ ì¸ì¦ ì •ë³´ ë¡œë“œ\n",
        "HF_TOKEN = userdata.get('HF_TOKEN') # Hugging Face ì•¡ì„¸ìŠ¤ í† í°\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # Google Custom Search API í‚¤\n",
        "GOOGLE_CSE_ID = userdata.get('GOOGLE_CSE_ID') # Programmable Search Engine ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s5yJb_xMUVnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0570c081-691a-48e0-cda1-ba1d4659acb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# 1. ë°ì´í„° ìˆ˜ì§‘ ë° ë²¡í„° ì €ì¥ì†Œ êµ¬ì¶• (NIH DSLD ì‚¬ìš©)\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3shlTdrtUXBg"
      },
      "outputs": [],
      "source": [
        "# NIH ì‹ì´ë³´ì¶©ì œ ë¼ë²¨ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ\n",
        "# loader = WebBaseLoader([\"https://dsld.od.nih.gov/dsld/\"])\n",
        "# documents = loader.load()\n",
        "\n",
        "# ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë°ì´í„° ë¡œë“œ\n",
        "loader = WebBaseLoader([\n",
        "    \"https://www.healthline.com/nutrition\",\n",
        "    \"https://examine.com/supplements/\",\n",
        "    \"https://www.iherb.com/c/Magnesium\",\n",
        "    \"https://www.iherb.com/c/Vitamin-B12\"\n",
        "    \"https://dsld.od.nih.gov/dsld/\"\n",
        "])\n",
        "documents = loader.load()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uw-n-TDgUYQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300bf140-e55d-4ede-d2a3-88895ff5fce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-319aacbaa380>:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n"
          ]
        }
      ],
      "source": [
        "# ë¬¸ì„œ ë¶„í•  (ì²­í¬ í¬ê¸° 512, 50% ì˜¤ë²„ë©)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=512, chunk_overlap=256\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# ì„ë² ë”© ëª¨ë¸ ì´ˆê¸°í™” (gte-base ì‚¬ìš©)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n",
        "\n",
        "# ChromaDBì— ë²¡í„° ì €ì¥\n",
        "vector_db = Chroma.from_documents(\n",
        "    texts, embeddings,\n",
        "    persist_directory=\"./chroma_db\",\n",
        "    collection_name=\"supplement_info\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zVPaQJ5CUaYe"
      },
      "outputs": [],
      "source": [
        "# 2. Google Programmable Search Engine ì„¤ì •\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query, num=3):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
        "    res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, num=num).execute()\n",
        "    return [item[\"snippet\"] for item in res[\"items\"]]\n",
        "\n",
        "# 3. Gemma-3B ëª¨ë¸ ì´ˆê¸°í™”\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-3-1b-it\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    token=HF_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xhiB8-ouUcFy"
      },
      "outputs": [],
      "source": [
        "# 4. ê³ ê¸‰ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ í…œí”Œë¦¿\n",
        "REACT_PROMPT = \"\"\"<start_of_turn>user\n",
        "ì‚¬ìš©ì ì •ë³´:\n",
        "{user_info}\n",
        "\n",
        "í˜„ì¬ ë‹¨ê³„: {step}\n",
        "ê³¼ê±° ê´€ì¸¡: {history}\n",
        "\n",
        "ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—…ì„ ë‹¤ìŒ í˜•ì‹ ì¤‘ í•˜ë‚˜ë¡œ ì¶œë ¥:\n",
        "1. ê²€ìƒ‰ í•„ìš”: \"Action: search[ê²€ìƒ‰ì–´]\"\n",
        "2. DB ì¡°íšŒ: \"Action: lookup[ì§ˆë¬¸]\"\n",
        "3. ìµœì¢… ë‹µë³€: \"Final Answer: [ë‹µë³€]\"\n",
        "\n",
        "ê·œì¹™:\n",
        "- ì˜í•™ì  ì¡°ì–¸ì€ ê³µì¸ëœ ì¶œì²˜ë¥¼ ë°˜ë“œì‹œ ì¸ìš©\n",
        "- ë³µìš©ëŸ‰ ê³„ì‚° ì‹œ ì‚¬ìš©ìì˜ ì‹ ì²´ ì¡°ê±´ ê³ ë ¤\n",
        "- ìƒí˜¸ì‘ìš© ê°€ëŠ¥ì„± ê²½ê³ <end_of_turn>\n",
        "<start_of_turn>assistant\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CQ_TGCVHUdea"
      },
      "outputs": [],
      "source": [
        "# 5. RAG ì—ì´ì „íŠ¸ ì‹¤í–‰ ë¡œì§\n",
        "def run_agent(user_input, max_steps=5):\n",
        "    history = []\n",
        "    for step in range(max_steps):\n",
        "        # ReAct í”„ë¡¬í”„íŠ¸ êµ¬ì„±\n",
        "        prompt = REACT_PROMPT.format(\n",
        "            user_info=user_input,\n",
        "            step=step+1,\n",
        "            history=\"\\n\".join(history[-3:])\n",
        "        )\n",
        "\n",
        "        # ëª¨ë¸ ì¶”ë¡ \n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n",
        "\n",
        "       # âœ… Step 1 ë˜ëŠ” 2ì—ì„œ Final Answer ë‚˜ì˜¤ë©´ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ step ì§„í–‰\n",
        "        if step < 2 and \"Final Answer:\" in response:\n",
        "            print(f\"Step {step + 1}ì—ì„œ Final Answerê°€ ë‚˜ì™€ì„œ ë¬´ì‹œí•˜ê³  ë‹¤ìŒ ìŠ¤í…ìœ¼ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.\")\n",
        "            continue\n",
        "\n",
        "        # âœ… Final Answer ë„ì¶œ ì‹œ ë°˜í™˜\n",
        "        if \"Final Answer:\" in response:\n",
        "            print(f\"\\nStep {step + 1}: ìµœì¢… ë‹µë³€ ìƒì„±\")\n",
        "            return response.split(\"Final Answer:\")[-1].strip()\n",
        "\n",
        "\n",
        "\n",
        "        # ì•¡ì…˜ íŒŒì‹±\n",
        "        if \"Final Answer:\" in response:\n",
        "            print(f\"\\nStep {step+1}: ìµœì¢… ë‹µë³€ ìƒì„±\")\n",
        "            return response.split(\"Final Answer:\")[-1].strip()\n",
        "\n",
        "        # ì•¡ì…˜ ì‹¤í–‰ ë° ê´€ì¸¡ ê¸°ë¡\n",
        "        action_type, query = parse_action(response)\n",
        "        observation = execute_action(action_type, query)\n",
        "\n",
        "        print(f\"\\nStep {step+1}:\")\n",
        "        print(f\"ìƒê°: {response.split('Action:')[0].strip()}\")\n",
        "        print(f\"ì•¡ì…˜: {action_type}({query})\")\n",
        "        print(f\"ê´€ì¸¡: {observation[:200]}...\")\n",
        "\n",
        "        history.append(f\"Step {step+1}: {observation[:200]}\")\n",
        "\n",
        "# ì•¡ì…˜ ì²˜ë¦¬ í•¨ìˆ˜\n",
        "def parse_action(response):\n",
        "    action_line = response.split(\"Action:\")[-1].split(\"\\n\")[0].strip()\n",
        "    if \"search[\" in action_line:\n",
        "        return \"search\", action_line.split(\"[\")[1].split(\"]\")[0]\n",
        "    elif \"lookup[\" in action_line:\n",
        "        return \"lookup\", action_line.split(\"[\")[1].split(\"]\")[0]\n",
        "    return \"unknown\", \"\"\n",
        "\n",
        "def execute_action(action_type, query):\n",
        "    if action_type == \"search\":\n",
        "        return \"\\n\".join(google_search(query))\n",
        "    elif action_type == \"lookup\":\n",
        "        docs = vector_db.similarity_search(query, k=3)\n",
        "        return \"\\n\".join([d.page_content for d in docs])\n",
        "    return \"No action performed\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REACT_PROMPT = \"\"\"<start_of_turn>user\n",
        "ì‚¬ìš©ì ì •ë³´:\n",
        "{user_info}\n",
        "\n",
        "í˜„ì¬ ë‹¨ê³„: {step}\n",
        "ê³¼ê±° ê´€ì¸¡: {history}\n",
        "\n",
        "ë‹¤ìŒ ë‹¨ê³„ì—ì„œ ìˆ˜í–‰í•´ì•¼ í•  ì‘ì—…ì„ ë‹¤ìŒ í˜•ì‹ ì¤‘ í•˜ë‚˜ë¡œ ì¶œë ¥:\n",
        "1. ê²€ìƒ‰ í•„ìš”: \"Action: search[ê²€ìƒ‰ì–´]\"\n",
        "2. DB ì¡°íšŒ: \"Action: lookup[ì§ˆë¬¸]\"\n",
        "3. ìµœì¢… ë‹µë³€: \"Final Answer: [ë‹µë³€]\"\n",
        "\n",
        "ê·œì¹™:\n",
        "- ë°˜ë“œì‹œ ìµœì†Œ 1íšŒ ì´ìƒ Action: search ë˜ëŠ” Action: lookupì„ ìˆ˜í–‰í•œ í›„ Final Answerë¥¼ ì¶œë ¥í•  ê²ƒ\n",
        "- ì›¹ì‚¬ì´íŠ¸ healthline, examine, iHerb ë˜ëŠ” NIH DSLDì—ì„œ ê·¼ê±°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•  ê²ƒ\n",
        "- ë‹µë³€ì€ 2~4ë¬¸ì¥ ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±\n",
        "- í•µì‹¬ ì„±ë¶„ì„ ëª…í™•íˆ ì–¸ê¸‰í•  ê²ƒ (ì˜ˆ: ê¸€ë£¨ì½”ì‚¬ë¯¼, ë§ˆê·¸ë„¤ìŠ˜ ë“±)\n",
        "- ì‹¤ì œ ì œí’ˆ ì˜ˆì‹œì™€ ê°€ê²© í¬í•¨ (ì˜ˆ: ë‹¥í„°ìŠ¤ë² ìŠ¤íŠ¸ ê¸€ë£¨ì½”ì‚¬ë¯¼ MSM, ì•½ 25,000ì›)\n",
        "- ë³µìš©ëŸ‰ì€ ì§§ê²Œ ì„¤ëª…\n",
        "- ì¼ë°˜ ì‚¬ìš©ìë„ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆë„ë¡ í•œê¸€ë¡œ ì‘ì„±\n",
        "<end_of_turn>\n",
        "<start_of_turn>assistant\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "tTl1mN5EDx_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rBKUb8jRUeyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f8d5e2-d685-42a3-9b4f-7db646036f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 1: ìµœì¢… ë‹µë³€ ìƒì„±\n",
            "\n",
            "ìµœì¢… ì¶”ì²œ:\n",
            "[ì¶”ì²œ ì˜ì–‘ì œ] (ì¶”ì²œ ì´ìœ  ë° ë³µìš©ëŸ‰ì€ ì•½ì‚¬ ë˜ëŠ” ì˜ì‚¬ì™€ ìƒë‹´ í›„ ê²°ì •í•´ì£¼ì„¸ìš”.)\"**\n",
            "\n",
            "**ì¶”ì²œ ì˜ì–‘ì œ (ì°¸ê³ ):**\n",
            "\n",
            "*   **ë§ˆê·¸ë„¤ìŠ˜:** ìŠ¤íŠ¸ë ˆìŠ¤ í•´ì†Œì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìœ¼ë©°, ê·¼ìœ¡ ì´ì™„ ë° ì‹ ê²½ ì•ˆì •ì— íš¨ê³¼ì ì…ë‹ˆë‹¤.\n",
            "    *   **ì¶”ì²œ ì œí’ˆ:**  ë§ˆê·¸ë„¤ìŠ˜ ì˜¥ì‹¤ ìˆë‹¤ëŠ” ì œí’ˆ (í•˜ë£¨ 100mg - 300mg ë³µìš©)\n",
            "    *   **ì°¸ê³ :**  ë§ˆê·¸ë„¤ìŠ˜ì€ ì²´ë‚´ ìˆ˜ë¶„ ê· í˜•ì„ ì¡°ì ˆí•˜ê³  ì‹ ê²½ ê¸°ëŠ¥ì„ ê°œì„ í•˜ì—¬ ìŠ¤íŠ¸ë ˆìŠ¤ ì™„í™”ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "*   **ë¹„íƒ€ë¯¼ Bêµ°:** ì‹ ê²½ ì•ˆì • ë° ìŠ¤íŠ¸ë ˆìŠ¤ í˜¸ë¥´ëª¬ ì¡°ì ˆì— ì¤‘ìš”í•©ë‹ˆë‹¤.\n",
            "    *   **ì¶”ì²œ ì œí’ˆ:**  ë¹„íƒ€ë¯¼ B12, ë¹„íƒ€ë¯¼ B6, ë¹„íƒ€ë¯¼ B1 (í•˜ë£¨ 100mg - 200mg ë³µìš©)\n",
            "    *   **ì°¸ê³ :** ë¹„íƒ€ë¯¼ Bêµ°ì€ ì‹ ê²½ ê¸°ëŠ¥ì„ ìœ ì§€í•˜ê³  ìŠ¤íŠ¸ë ˆìŠ¤ì— ëŒ€í•œ ì €í•­ë ¥ì„ ë†’ì´ëŠ” ë° ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "*   **ì˜¤ë©”ê°€-3 ì§€ë°©ì‚°:** í•­ì—¼ì¦ íš¨ê³¼ê°€ ìˆì–´ ìŠ¤íŠ¸ë ˆìŠ¤ ê´€ë ¨ ì—¼ì¦ì„ ì™„í™”í•˜ê³  ì‹¬ë¦¬ì  ì•ˆì •ì— ë„ì›€ì„ ì¤„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "    *   **\n"
          ]
        }
      ],
      "source": [
        "# # 6. ì‹¤í–‰ ì˜ˆì‹œ\n",
        "# user_input = \"\"\"\n",
        "# 30ëŒ€ ì§ì¥ì¸ì¸ë° ìŠ¤íŠ¸ë ˆìŠ¤ê°€ ì˜ ìŒ“ì´ê³  ì‰½ê²Œ í”¼ê³¤í•´ì§‘ë‹ˆë‹¤.\n",
        "# ì˜ ì§€ì¹˜ë‹ˆ ê¸°ë¶„ë„ ë³„ë¡œì—ìš”. ì–´ë–¤ ì˜ì–‘ì œ ì œí’ˆì„ ë¨¹ìœ¼ë©´ ì¢‹ì„ì§€ ì¶”ì²œí•´ì£¼ì„¸ìš”.\n",
        "# ë‹µë³€ì€ í•œê¸€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.\n",
        "# \"\"\"\n",
        "\n",
        "# result = run_agent(user_input)\n",
        "# print(\"\\nìµœì¢… ì¶”ì²œ:\")\n",
        "# print(result)\n",
        "\n",
        "# # 6. ì‹¤í–‰ ì˜ˆì‹œ (ì‹¤í–‰ ì¤‘ ì‚¬ìš©ìì—ê²Œ ì…ë ¥ ë°›ìŒ)\n",
        "# user_input = input(\"ë‹¹ì‹ ì˜ ì¦ìƒì´ë‚˜ ê±´ê°• ê³ ë¯¼ì„ ììœ ë¡­ê²Œ ì…ë ¥í•˜ì„¸ìš”:\\n\")\n",
        "\n",
        "# result = run_agent(user_input)\n",
        "# print(\"\\nâœ… ìµœì¢… ì¶”ì²œ:\")\n",
        "# print(result)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "def search_google(query):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
        "    res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, num=3).execute()\n",
        "    return [item[\"snippet\"] for item in res[\"items\"]]\n",
        "\n",
        "def query_vector_db(query):\n",
        "    results = vector_db.similarity_search(query, k=3)\n",
        "    return [doc.page_content[:200] for doc in results]\n",
        "\n",
        "def recommend_supplement(symptom):\n",
        "    print(f\"ğŸ” ì¦ìƒ ê¸°ë°˜ Function í˜¸ì¶œ ì¤‘: {symptom}\")\n",
        "\n",
        "    # Step 1: Google ê²€ìƒ‰\n",
        "    google_info = search_google(f\"{symptom}ì— ì¢‹ì€ ì˜ì–‘ì œ\")\n",
        "\n",
        "    # Step 2: ë²¡í„° DB ê²€ìƒ‰\n",
        "    db_info = query_vector_db(symptom)\n",
        "\n",
        "    # Step 3: LLM ìš”ì•½ìš© í”„ë¡¬í”„íŠ¸ ìƒì„±\n",
        "    prompt = f\"\"\"\n",
        "ë„ˆëŠ” ê±´ê°• ì „ë¬¸ê°€ AIì•¼. ì•„ë˜ ì¦ìƒì— ëŒ€í•´ êµ¬ê¸€ê³¼ DB ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì¶”ì²œ ì˜ì–‘ì œë¥¼ ì•Œë ¤ì¤˜.\n",
        "\n",
        "ì¦ìƒ: {symptom}\n",
        "\n",
        "ğŸ”¹ Google ê²€ìƒ‰ ê²°ê³¼:\n",
        "{google_info}\n",
        "\n",
        "ğŸ”¹ DB ìœ ì‚¬ ë¬¸ì„œ:\n",
        "{db_info}\n",
        "\n",
        "ë‹µë³€ì€ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¶œë ¥:\n",
        "1. ì¶”ì²œ ì„±ë¶„ (ì˜ˆ: ë§ˆê·¸ë„¤ìŠ˜, ê¸€ë£¨ì½”ì‚¬ë¯¼)\n",
        "2. ì¶”ì²œ ì œí’ˆ ì˜ˆì‹œì™€ ê°€ê²©\n",
        "3. ì§§ì€ ë³µìš© ë°©ë²•\n",
        "\n",
        "â€» ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±, ì¼ë°˜ ì‚¬ìš©ìë„ ì´í•´ ê°€ëŠ¥í•˜ê²Œ ì‘ì„±í•´ì¤˜.\n",
        "\"\"\"\n",
        "\n",
        "    # Step 4: LLM í˜¸ì¶œ\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=400)\n",
        "    return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9lNBsC6hLZ3W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ì‹¤í–‰\n",
        "user_input = input(\"ë‹¹ì‹ ì˜ ì¦ìƒì´ë‚˜ ê±´ê°• ê³ ë¯¼ì„ ì…ë ¥í•˜ì„¸ìš”:\\n\")\n",
        "final_response = recommend_supplement(user_input)\n",
        "\n",
        "print(\"\\nâœ… ìµœì¢… ì¶”ì²œ ê²°ê³¼:\")\n",
        "print(final_response)\n"
      ],
      "metadata": {
        "id": "TJBa_brFLcWg"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}