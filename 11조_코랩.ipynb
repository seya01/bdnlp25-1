{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "_drIBRDyUTE8"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install -q transformers chromadb langchain-community google-api-python-client huggingface_hub sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "xVo0GksFUUbQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Colab Secrets에서 인증 정보 로드\n",
        "HF_TOKEN = userdata.get('HF_TOKEN') # Hugging Face 액세스 토큰\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # Google Custom Search API 키\n",
        "GOOGLE_CSE_ID = userdata.get('GOOGLE_CSE_ID') # Programmable Search Engine ID"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "s5yJb_xMUVnm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0570c081-691a-48e0-cda1-ba1d4659acb3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ],
      "source": [
        "# 1. 데이터 수집 및 벡터 저장소 구축 (NIH DSLD 사용)\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "3shlTdrtUXBg"
      },
      "outputs": [],
      "source": [
        "# NIH 식이보충제 라벨 데이터베이스에서 데이터 로드\n",
        "loader = WebBaseLoader([\"https://dsld.od.nih.gov/dsld/\"])\n",
        "documents = loader.load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Uw-n-TDgUYQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "300bf140-e55d-4ede-d2a3-88895ff5fce5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-5-319aacbaa380>:8: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
            "  embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n"
          ]
        }
      ],
      "source": [
        "# 문서 분할 (청크 크기 512, 50% 오버랩)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=512, chunk_overlap=256\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 임베딩 모델 초기화 (gte-base 사용)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n",
        "\n",
        "# ChromaDB에 벡터 저장\n",
        "vector_db = Chroma.from_documents(\n",
        "    texts, embeddings,\n",
        "    persist_directory=\"./chroma_db\",\n",
        "    collection_name=\"supplement_info\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "zVPaQJ5CUaYe"
      },
      "outputs": [],
      "source": [
        "# 2. Google Programmable Search Engine 설정\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query, num=3):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
        "    res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, num=num).execute()\n",
        "    return [item[\"snippet\"] for item in res[\"items\"]]\n",
        "\n",
        "# 3. Gemma-3B 모델 초기화\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-3-1b-it\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    token=HF_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "xhiB8-ouUcFy"
      },
      "outputs": [],
      "source": [
        "# 4. 고급 프롬프트 엔지니어링 템플릿\n",
        "REACT_PROMPT = \"\"\"<start_of_turn>user\n",
        "사용자 정보:\n",
        "{user_info}\n",
        "\n",
        "현재 단계: {step}\n",
        "과거 관측: {history}\n",
        "\n",
        "다음 단계에서 수행해야 할 작업을 다음 형식 중 하나로 출력:\n",
        "1. 검색 필요: \"Action: search[검색어]\"\n",
        "2. DB 조회: \"Action: lookup[질문]\"\n",
        "3. 최종 답변: \"Final Answer: [답변]\"\n",
        "\n",
        "규칙:\n",
        "- 의학적 조언은 공인된 출처를 반드시 인용\n",
        "- 복용량 계산 시 사용자의 신체 조건 고려\n",
        "- 상호작용 가능성 경고<end_of_turn>\n",
        "<start_of_turn>assistant\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "CQ_TGCVHUdea"
      },
      "outputs": [],
      "source": [
        "# 5. RAG 에이전트 실행 로직\n",
        "def run_agent(user_input, max_steps=5):\n",
        "    history = []\n",
        "    for step in range(max_steps):\n",
        "        # ReAct 프롬프트 구성\n",
        "        prompt = REACT_PROMPT.format(\n",
        "            user_info=user_input,\n",
        "            step=step+1,\n",
        "            history=\"\\n\".join(history[-3:])\n",
        "        )\n",
        "\n",
        "        # 모델 추론\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # 액션 파싱\n",
        "        if \"Final Answer:\" in response:\n",
        "            print(f\"\\nStep {step+1}: 최종 답변 생성\")\n",
        "            return response.split(\"Final Answer:\")[-1].strip()\n",
        "\n",
        "        # 액션 실행 및 관측 기록\n",
        "        action_type, query = parse_action(response)\n",
        "        observation = execute_action(action_type, query)\n",
        "\n",
        "        print(f\"\\nStep {step+1}:\")\n",
        "        print(f\"생각: {response.split('Action:')[0].strip()}\")\n",
        "        print(f\"액션: {action_type}({query})\")\n",
        "        print(f\"관측: {observation[:200]}...\")\n",
        "\n",
        "        history.append(f\"Step {step+1}: {observation[:200]}\")\n",
        "\n",
        "# 액션 처리 함수\n",
        "def parse_action(response):\n",
        "    action_line = response.split(\"Action:\")[-1].split(\"\\n\")[0].strip()\n",
        "    if \"search[\" in action_line:\n",
        "        return \"search\", action_line.split(\"[\")[1].split(\"]\")[0]\n",
        "    elif \"lookup[\" in action_line:\n",
        "        return \"lookup\", action_line.split(\"[\")[1].split(\"]\")[0]\n",
        "    return \"unknown\", \"\"\n",
        "\n",
        "def execute_action(action_type, query):\n",
        "    if action_type == \"search\":\n",
        "        return \"\\n\".join(google_search(query))\n",
        "    elif action_type == \"lookup\":\n",
        "        docs = vector_db.similarity_search(query, k=3)\n",
        "        return \"\\n\".join([d.page_content for d in docs])\n",
        "    return \"No action performed\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "rBKUb8jRUeyG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3f8d5e2-d685-42a3-9b4f-7db646036f76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Step 1: 최종 답변 생성\n",
            "\n",
            "최종 추천:\n",
            "[추천 영양제] (추천 이유 및 복용량은 약사 또는 의사와 상담 후 결정해주세요.)\"**\n",
            "\n",
            "**추천 영양제 (참고):**\n",
            "\n",
            "*   **마그네슘:** 스트레스 해소에 도움을 줄 수 있으며, 근육 이완 및 신경 안정에 효과적입니다.\n",
            "    *   **추천 제품:**  마그네슘 옥실 있다는 제품 (하루 100mg - 300mg 복용)\n",
            "    *   **참고:**  마그네슘은 체내 수분 균형을 조절하고 신경 기능을 개선하여 스트레스 완화에 도움을 줄 수 있습니다.\n",
            "*   **비타민 B군:** 신경 안정 및 스트레스 호르몬 조절에 중요합니다.\n",
            "    *   **추천 제품:**  비타민 B12, 비타민 B6, 비타민 B1 (하루 100mg - 200mg 복용)\n",
            "    *   **참고:** 비타민 B군은 신경 기능을 유지하고 스트레스에 대한 저항력을 높이는 데 도움을 줄 수 있습니다.\n",
            "*   **오메가-3 지방산:** 항염증 효과가 있어 스트레스 관련 염증을 완화하고 심리적 안정에 도움을 줄 수 있습니다.\n",
            "    *   **\n"
          ]
        }
      ],
      "source": [
        "# 6. 실행 예시\n",
        "user_input = \"\"\"\n",
        "30대 직장인인데 스트레스가 잘 쌓이고 쉽게 피곤해집니다.\n",
        "잘 지치니 기분도 별로에요. 어떤 영양제 제품을 먹으면 좋을지 추천해주세요.\n",
        "답변은 한글로 작성해주세요.\n",
        "\"\"\"\n",
        "\n",
        "result = run_agent(user_input)\n",
        "print(\"\\n최종 추천:\")\n",
        "print(result)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}