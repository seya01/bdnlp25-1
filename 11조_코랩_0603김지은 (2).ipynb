{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "_drIBRDyUTE8"
      },
      "outputs": [],
      "source": [
        "# 필요한 라이브러리 설치\n",
        "!pip install -q transformers chromadb langchain-community google-api-python-client huggingface_hub sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "xVo0GksFUUbQ"
      },
      "outputs": [],
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "# Colab Secrets에서 인증 정보 로드\n",
        "#HF_TOKEN = userdata.get('xxxxxxxx') # Hugging Face 액세스 토큰\n",
        "#GOOGLE_API_KEY = userdata.get('xxxxxxxxxxxx') # Google Custom Search API 키\n",
        "#GOOGLE_CSE_ID = userdata.get('xxxxxxxxxxxxxxxx') # Programmable Search Engine ID\n",
        "\n",
        "HF_TOKEN = \"xxxxxxxxxxxxxx\"\n",
        "GOOGLE_API_KEY = \"xxxxxxxxxxxxxxxxx\"\n",
        "GOOGLE_CSE_ID = \"xxxxxxxxxxxxxxx\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "s5yJb_xMUVnm"
      },
      "outputs": [],
      "source": [
        "# 1. 데이터 수집 및 벡터 저장소 구축 (NIH DSLD 사용)\n",
        "from langchain.document_loaders import WebBaseLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import Chroma\n",
        "from langchain.embeddings import HuggingFaceEmbeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "3shlTdrtUXBg"
      },
      "outputs": [],
      "source": [
        "# 데이터베이스에서 데이터 로드\n",
        "loader = WebBaseLoader([\n",
        "    \"https://www.healthline.com/nutrition\",\n",
        "    \"https://examine.com/supplements/\",\n",
        "    \"https://www.iherb.com/c/Magnesium\",\n",
        "    \"https://www.iherb.com/c/Vitamin-B12\"\n",
        "    \"https://dsld.od.nih.gov/dsld/\"\n",
        "])\n",
        "documents = loader.load()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "Uw-n-TDgUYQL"
      },
      "outputs": [],
      "source": [
        "# 문서 분할 (청크 크기 512, 50% 오버랩)\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=512, chunk_overlap=256\n",
        ")\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "# 임베딩 모델 초기화 (gte-base 사용)\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"thenlper/gte-base\")\n",
        "\n",
        "# ChromaDB에 벡터 저장\n",
        "vector_db = Chroma.from_documents(\n",
        "    texts, embeddings,\n",
        "    persist_directory=\"./chroma_db\",\n",
        "    collection_name=\"supplement_info\"\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "zVPaQJ5CUaYe"
      },
      "outputs": [],
      "source": [
        "# 2. Google Programmable Search Engine 설정\n",
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query, num=3):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
        "    res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, num=num).execute()\n",
        "    return [item[\"snippet\"] for item in res[\"items\"]]\n",
        "\n",
        "# 3. Gemma-3B 모델 초기화\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-3-1b-it\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,\n",
        "    token=HF_TOKEN\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "\n",
        "# 1. 로그인 (선택적이지만 확실하게 처리)\n",
        "login(token=\"xxxxxxxxxxxxx\")  # 토큰 전체 입력\n",
        "\n",
        "# 2. 모델과 토크나이저 로딩 (토큰 명시)\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"google/gemma-3-1b-it\", token=\"xxxxxxxxxxxxxxxxxxxx\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"google/gemma-3-1b-it\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.bfloat16,  # 또는 torch.float32 (Colab CPU 환경이라면)\n",
        "    token=\"xxxxxxxxxxxxxxxxxxxxxxxx\"\n",
        ")\n"
      ],
      "metadata": {
        "id": "pELq4tpGZtCp"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "id": "xhiB8-ouUcFy"
      },
      "outputs": [],
      "source": [
        "# 4. 고급 프롬프트 엔지니어링 템플릿\n",
        "REACT_PROMPT = \"\"\"<start_of_turn>user\n",
        "사용자 정보:\n",
        "{user_info}\n",
        "\n",
        "현재 단계: {step}\n",
        "과거 관측: {history}\n",
        "\n",
        "다음 단계에서 수행해야 할 작업을 다음 형식 중 하나로 출력:\n",
        "1. 검색 필요: \"Action: search[검색어]\"\n",
        "2. DB 조회: \"Action: lookup[질문]\"\n",
        "3. 최종 답변: \"Final Answer: [답변]\"\n",
        "\n",
        "규칙:\n",
        "- 의학적 조언은 공인된 출처를 반드시 인용\n",
        "- 복용량 계산 시 사용자의 신체 조건 고려\n",
        "- 상호작용 가능성 경고\n",
        "<end_of_turn>\n",
        "<start_of_turn>assistant\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "CQ_TGCVHUdea"
      },
      "outputs": [],
      "source": [
        "def run_agent(user_input, max_steps=5):\n",
        "    history = []\n",
        "    for step in range(max_steps):\n",
        "        # ReAct 프롬프트 구성\n",
        "        prompt = REACT_PROMPT.format(\n",
        "            user_info=user_input,\n",
        "            step=step + 1,\n",
        "            history=\"\\n\".join(history[-3:])\n",
        "        )\n",
        "\n",
        "        # 모델 추론\n",
        "        inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "        outputs = model.generate(**inputs, max_new_tokens=500)\n",
        "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "        # ✅ Step 1 또는 2에서 Final Answer 나오면 무시하고 다음 step 진행\n",
        "        if step < 2 and \"Final Answer:\" in response:\n",
        "            print(f\"Step {step + 1}에서 Final Answer가 나와서 무시하고 다음 스텝으로 진행합니다.\")\n",
        "            continue\n",
        "\n",
        "        # ✅ Final Answer 도출 시 반환\n",
        "        if \"Final Answer:\" in response:\n",
        "            print(f\"\\nStep {step + 1}: 최종 답변 생성\")\n",
        "            return response.split(\"Final Answer:\")[-1].strip()\n",
        "\n",
        "        # ✅ 액션 파싱 및 실행\n",
        "        action_type, query = parse_action(response)\n",
        "        observation = execute_action(action_type, query)\n",
        "\n",
        "        print(f\"\\nStep {step + 1}:\")\n",
        "        print(f\"생각: {response.split('Action:')[0].strip()}\")\n",
        "        print(f\"액션: {action_type}({query})\")\n",
        "        print(f\"관측: {observation[:200]}...\")\n",
        "\n",
        "        # ✅ 관측 결과 저장\n",
        "        history.append(f\"Step {step + 1}: {observation[:200]}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "rBKUb8jRUeyG"
      },
      "outputs": [],
      "source": [
        "# # 6. 실행 예시\n",
        "# user_input = \"\"\"\n",
        "# 30대 직장인인데 스트레스가 잘 쌓이고 쉽게 피곤해집니다.\n",
        "# 잘 지치니 기분도 별로에요. 어떤 영양제 제품을 먹으면 좋을지 추천해주세요.\n",
        "# 답변은 한글로 작성해주세요.\n",
        "# \"\"\"\n",
        "\n",
        "# result = run_agent(user_input)\n",
        "# print(\"\\n최종 추천:\")\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "REACT_PROMPT = \"\"\"<start_of_turn>user\n",
        "사용자 정보:\n",
        "{user_info}\n",
        "\n",
        "현재 단계: {step}\n",
        "과거 관측: {history}\n",
        "\n",
        "다음 단계에서 수행해야 할 작업을 다음 형식 중 하나로 출력:\n",
        "1. 검색 필요: \"Action: search[검색어]\"\n",
        "2. DB 조회: \"Action: lookup[질문]\"\n",
        "3. 최종 답변: \"Final Answer: [답변]\"\n",
        "\n",
        "규칙:\n",
        "- 반드시 최소 1회 이상 Action: search 또는 Action: lookup을 수행한 후 Final Answer를 출력할 것\n",
        "- 웹사이트 healthline, examine, iHerb 또는 NIH DSLD에서 근거를 기반으로 할 것\n",
        "- 답변은 2~4문장 이내로 간결하게 작성\n",
        "- 핵심 성분을 명확히 언급할 것 (예: 글루코사민, 마그네슘 등)\n",
        "- 실제 제품 예시와 가격 포함 (예: 닥터스베스트 글루코사민 MSM, 약 25,000원)\n",
        "- 복용량은 짧게 설명\n",
        "- 일반 사용자도 쉽게 이해할 수 있도록 한글로 작성\n",
        "<end_of_turn>\n",
        "<start_of_turn>assistant\n",
        "\"\"\"\n"
      ],
      "metadata": {
        "id": "i-CCCUI7bYgb"
      },
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. 실행 예시 (실행 중 사용자에게 입력 받음)\n",
        "user_input = input(\"당신의 증상이나 건강 고민을 자유롭게 입력하세요:\\n\")\n",
        "\n",
        "result = run_agent(user_input)\n",
        "print(\"\\n✅ 최종 추천:\")\n",
        "print(result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPiGSE0CWdTC",
        "outputId": "8ea7dcd5-56b6-43a5-e09a-dd69ab3aa77f"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "당신의 증상이나 건강 고민을 자유롭게 입력하세요:\n",
            "90세야. 무릎관절아파\n",
            "Step 1에서 Final Answer가 나와서 무시하고 다음 스텝으로 진행합니다.\n",
            "Step 2에서 Final Answer가 나와서 무시하고 다음 스텝으로 진행합니다.\n",
            "\n",
            "Step 3: 최종 답변 생성\n",
            "\n",
            "✅ 최종 추천:\n",
            "** 무릎 관절 통증은 다양한 원인으로 발생할 수 있습니다. 특히 노년층의 경우 관절 연골 손상,  퇴행성 관절염, 과도한 체중 등으로 인해 통증이 심해질 수 있습니다. 글루코사민과 마그네슘은 관절 건강에 도움이 될 수 있습니다.\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}