{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜"
      ],
      "metadata": {
        "id": "sdt31l8m9FGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q chromadb sentence-transformers openai # easyocr opencv-python"
      ],
      "metadata": {
        "id": "jx0tC1_b8oDa",
        "outputId": "c1115838-02b7-42bb-b97b-9fb2a8be991a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/67.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m19.3/19.3 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m49.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m65.8/65.8 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m55.7/55.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m196.2/196.2 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m118.5/118.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m102.5/102.5 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m66.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# API Key í™˜ê²½ ì„¤ì •"
      ],
      "metadata": {
        "id": "B6ed6KuM9a0F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "HF_TOKEN = userdata.get('HF_TOKEN') # Hugging Face Token\n",
        "GOOGLE_API_KEY = userdata.get('GOOGLE_API_KEY') # Google Custom Search API í‚¤\n",
        "GOOGLE_CSE_ID = userdata.get('GOOGLE_CSE_ID') # Programmable Search Engine ID\n",
        "OPENAI_API_KEY = userdata.get('OPENAI_API_KEY') # OpenAI API Key\n",
        "client_id = userdata.get('NAVER_CLIENT_ID') # Naver Client Key\n",
        "client_secret = userdata.get('NAVER_CLIENT_SECRET') # Naver Client Secret\n",
        "gpt_target = \"gpt-4.1-mini\""
      ],
      "metadata": {
        "id": "eMmaVqIk9aFh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Knowledge ìˆ˜ì§‘ìš© ë„¤ì´ë²„ì‡¼í•‘ ì˜ì–‘ì œ ìƒí’ˆ ê²€ìƒ‰ ì½”ë“œ"
      ],
      "metadata": {
        "id": "_MP-nZVT9IJs"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zkuqQr7qfAvb"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from urllib.parse import quote\n",
        "\n",
        "def naver_shop_search(query, display=100):\n",
        "    encoded_query = quote(query)\n",
        "    url = f\"https://openapi.naver.com/v1/search/shop.json?query={encoded_query}&display={display}&start=1&sort=sim&exclude=used:cbshop:rental\"\n",
        "\n",
        "    headers = {\n",
        "        \"X-Naver-Client-Id\": client_id,\n",
        "        \"X-Naver-Client-Secret\": client_secret\n",
        "    }\n",
        "\n",
        "    response = requests.get(url, headers=headers)\n",
        "\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        return {\"error\": response.status_code}\n",
        "\n",
        "result = naver_shop_search(\"ì˜ì–‘ì œ\", 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ì„ ìœ„í•œ êµ¬ê¸€ ê²€ìƒ‰ ì½”ë“œ"
      ],
      "metadata": {
        "id": "QkMiqKHE9k6E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from googleapiclient.discovery import build\n",
        "\n",
        "def google_search(query, num=10):\n",
        "    service = build(\"customsearch\", \"v1\", developerKey=GOOGLE_API_KEY)\n",
        "    res = service.cse().list(q=query, cx=GOOGLE_CSE_ID, num=num).execute()\n",
        "    return [item[\"snippet\"] for item in res[\"items\"]]\n"
      ],
      "metadata": {
        "id": "tQqNfgec9kFO"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Base Knowledgeë¥¼ Vector DBì— ì €ì¥í•˜ëŠ” ì½”ë“œ"
      ],
      "metadata": {
        "id": "0nDp44_D9K8M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ë„¤ì´ë²„ì‡¼í•‘ ê²€ìƒ‰ ê²°ê³¼ -> Vector DB (Chroma) ì €ì¥\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# import cv2\n",
        "# import easyocr\n",
        "# import requests\n",
        "# import numpy as np\n",
        "# from matplotlib import pyplot as plt\n",
        "# import logging\n",
        "# logging.getLogger('easyocr').setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "# def image_recognition(image_url):\n",
        "#   if image_url:\n",
        "#     response = requests.get(image_url)\n",
        "#     image_array = np.asarray(bytearray(response.content), dtype=np.uint8)\n",
        "#     img = cv2.imdecode(image_array, cv2.IMREAD_COLOR)\n",
        "#     if img is not None: # Add this check\n",
        "#         reader = easyocr.Reader(['en', 'ko'])\n",
        "#         results = []\n",
        "#         try:\n",
        "#           results = reader.readtext(img)\n",
        "#         except Exception as e: # Catch specific exceptions if possible, or log the error\n",
        "#           print(f\"Error reading image text for {image_url}: {e}\") # Log the error\n",
        "#         textlist = []\n",
        "#         for box,text,conf in results:\n",
        "#           if text:\n",
        "#             textlist.append(text)\n",
        "#         return ','.join(textlist)\n",
        "#     else:\n",
        "#       print(f\"Failed to decode image from URL: {image_url}\") # Log decoding failure\n",
        "#       return ''\n",
        "#   else:\n",
        "#     return ''\n",
        "\n",
        "# ë°ì´í„° ì „ì²˜ë¦¬\n",
        "def preprocess_items(items):\n",
        "    processed = []\n",
        "    count=1\n",
        "    for item in items:\n",
        "        data = {\n",
        "            \"id\": item['productId'],\n",
        "            \"text\": f\"{item['title']} {item['brand']} {item['maker']} {item['category3']} {item['category4']}\",  # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸\n",
        "            \"metadata\": {\n",
        "                \"price\": int(item['lprice']),\n",
        "                \"brand\": item['brand'],\n",
        "                \"category\": f\"{item['category1']}>{item['category2']}>{item['category3']}>{item['category4']}\",\n",
        "                \"link\": item['link'],\n",
        "                # \"imagetext\": image_recognition(item['image'])\n",
        "                \"imagelink\": (item['image'])\n",
        "            }\n",
        "        }\n",
        "        processed.append(data)\n",
        "        print(f\"\\r count : {count} / {len(items)}\", end=\"\")\n",
        "        count+=1\n",
        "    print()\n",
        "    return processed\n",
        "\n",
        "# Chroma DB ì´ˆê¸°í™”\n",
        "client = chromadb.PersistentClient(path=\"./naver_shopping_db\")\n",
        "embedding_model = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
        "    model_name=\"sentence-transformers/paraphrase-multilingual-mpnet-base-v2\", token=HF_TOKEN\n",
        ")\n",
        "# ê¸°ì¡´ ì»¬ë ‰ì…˜ì´ ìˆìœ¼ë©´ ì‚­ì œ í›„ ì¬ìƒì„±\n",
        "try:\n",
        "    client.delete_collection(\"products\")\n",
        "except:\n",
        "    pass\n",
        "collection = client.create_collection(\n",
        "    name=\"products\",\n",
        "    embedding_function=embedding_model,\n",
        "    metadata={\"hnsw:space\": \"cosine\"}\n",
        ")\n",
        "\n",
        "# ë°ì´í„° ì €ì¥\n",
        "if 'items' in result:\n",
        "    processed_data = preprocess_items(result['items'])\n",
        "    collection.add(\n",
        "        ids=[item['id'] for item in processed_data],\n",
        "        documents=[item['text'] for item in processed_data],\n",
        "        metadatas=[item['metadata'] for item in processed_data]\n",
        "    )\n",
        "    print(\"ì„±ê³µì ìœ¼ë¡œ\", len(processed_data), \"ê°œ ìƒí’ˆ ì €ì¥ë¨\")\n",
        "else:\n",
        "    print(\"Error:\", result.get('error', 'ë°ì´í„° ì—†ìŒ'))"
      ],
      "metadata": {
        "id": "04HhIARLgZcr",
        "outputId": "6ea4bb36-84e4-4c63-b896-bb341e369152",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r count : 1 / 100\r count : 2 / 100\r count : 3 / 100\r count : 4 / 100\r count : 5 / 100\r count : 6 / 100\r count : 7 / 100\r count : 8 / 100\r count : 9 / 100\r count : 10 / 100\r count : 11 / 100\r count : 12 / 100\r count : 13 / 100\r count : 14 / 100\r count : 15 / 100\r count : 16 / 100\r count : 17 / 100\r count : 18 / 100\r count : 19 / 100\r count : 20 / 100\r count : 21 / 100\r count : 22 / 100\r count : 23 / 100\r count : 24 / 100\r count : 25 / 100\r count : 26 / 100\r count : 27 / 100\r count : 28 / 100\r count : 29 / 100\r count : 30 / 100\r count : 31 / 100\r count : 32 / 100\r count : 33 / 100\r count : 34 / 100\r count : 35 / 100\r count : 36 / 100\r count : 37 / 100\r count : 38 / 100\r count : 39 / 100\r count : 40 / 100\r count : 41 / 100\r count : 42 / 100\r count : 43 / 100\r count : 44 / 100\r count : 45 / 100\r count : 46 / 100\r count : 47 / 100\r count : 48 / 100\r count : 49 / 100\r count : 50 / 100\r count : 51 / 100\r count : 52 / 100\r count : 53 / 100\r count : 54 / 100\r count : 55 / 100\r count : 56 / 100\r count : 57 / 100\r count : 58 / 100\r count : 59 / 100\r count : 60 / 100\r count : 61 / 100\r count : 62 / 100\r count : 63 / 100\r count : 64 / 100\r count : 65 / 100\r count : 66 / 100\r count : 67 / 100\r count : 68 / 100\r count : 69 / 100\r count : 70 / 100\r count : 71 / 100\r count : 72 / 100\r count : 73 / 100\r count : 74 / 100\r count : 75 / 100\r count : 76 / 100\r count : 77 / 100\r count : 78 / 100\r count : 79 / 100\r count : 80 / 100\r count : 81 / 100\r count : 82 / 100\r count : 83 / 100\r count : 84 / 100\r count : 85 / 100\r count : 86 / 100\r count : 87 / 100\r count : 88 / 100\r count : 89 / 100\r count : 90 / 100\r count : 91 / 100\r count : 92 / 100\r count : 93 / 100\r count : 94 / 100\r count : 95 / 100\r count : 96 / 100\r count : 97 / 100\r count : 98 / 100\r count : 99 / 100\r count : 100 / 100\n",
            "ì„±ê³µì ìœ¼ë¡œ 100 ê°œ ìƒí’ˆ ì €ì¥ë¨\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector DB ê²€ìƒ‰ ì½”ë“œ"
      ],
      "metadata": {
        "id": "3iaTkTCqVcDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vectordb_search(query, n_results=10):\n",
        "    results = collection.query(\n",
        "        query_texts=[query],\n",
        "        n_results=n_results\n",
        "    )\n",
        "    output = []\n",
        "    for idx, (doc, meta) in enumerate(zip(results['documents'][0], results['metadatas'][0]), 1):\n",
        "        output.append({\n",
        "            \"ì œí’ˆì •ë³´\": doc,\n",
        "            \"ë©”íƒ€ë°ì´í„°\": meta\n",
        "        })\n",
        "    return output\n",
        "vectordb_search(\"ë¹„íƒ€ë¯¼\")"
      ],
      "metadata": {
        "id": "NPhiJj3qVbdY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d8596dc-099e-4755-fdad-81e969a6c0fc"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'ì œí’ˆì •ë³´': 'ì•„ì„ë¹„íƒ€ ë©€í‹° ë¹„íƒ€ë¯¼ ì´ë®¨ í”ŒëŸ¬ìŠ¤ 7ì¼ ìƒ· ì¢…ê·¼ë‹¹ ì•¡ìƒ ì•„ì´ì—  ë¹„íƒ€ ì´ë¬¸ ì¢…í•© ì¢…ê·¼ë‹¹  ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'brand': 'ì¢…ê·¼ë‹¹',\n",
              "   'imagelink': 'https://shopping-phinf.pstatic.net/main_8660875/86608759572.7.jpg',\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'link': 'https://smartstore.naver.com/main/products/9064259249',\n",
              "   'price': 11880}},\n",
              " {'ì œí’ˆì •ë³´': 'ì„¼íŠ¸ë£¸ ì‹¤ë²„ í¬ ìš°ë¨¼ ì¢…í•© ë©€í‹° ë¹„íƒ€ë¯¼ <b>ì˜ì–‘ì œ</b> 112ì • ì½”ìŠ¤íŠ¸ì½” ë¹„íƒ€ë¯¼B12 ëŒ€ìš©ëŸ‰ ì„¼íŠ¸ë£¸ í™”ì´ì ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'price': 34900,\n",
              "   'imagelink': 'https://shopping-phinf.pstatic.net/main_8678780/86787803460.8.jpg',\n",
              "   'link': 'https://smartstore.naver.com/main/products/9243303137',\n",
              "   'brand': 'ì„¼íŠ¸ë£¸'}},\n",
              " {'ì œí’ˆì •ë³´': 'ì•”ì›¨ì´ ë”ë¸”ì—‘ìŠ¤ ë¦¬í•„ ì¢…í•©ë¹„íƒ€ë¯¼ ë¯¸ë„¤ë„ ë‰´íŠ¸ë¦¬ë¼ì´íŠ¸ ì•”ì›¨ì´  ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'price': 68000,\n",
              "   'brand': 'ì•”ì›¨ì´',\n",
              "   'link': 'https://smartstore.naver.com/main/products/5748609307',\n",
              "   'imagelink': 'https://shopping-phinf.pstatic.net/main_8329310/83293108601.13.jpg',\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼'}},\n",
              " {'ì œí’ˆì •ë³´': 'ì„¼íŠ¸ë£¸ ì‹¤ë²„ í¬ ë§¨ ì¢…í•© ë©€í‹° ë¹„íƒ€ë¯¼ 112ì • ì½”ìŠ¤íŠ¸ì½” ë‚¨ì„± 50+ ëŒ€ìš©ëŸ‰ <b>ì˜ì–‘ì œ</b> ì„¼íŠ¸ë£¸ í™”ì´ì ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'link': 'https://smartstore.naver.com/main/products/9244093197',\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'brand': 'ì„¼íŠ¸ë£¸',\n",
              "   'imagelink': 'https://shopping-phinf.pstatic.net/main_8678859/86788593520.4.jpg',\n",
              "   'price': 34900}},\n",
              " {'ì œí’ˆì •ë³´': 'ì¢…ê·¼ë‹¹ ì•„ì„ë¹„íƒ€ ë©€í‹°ë¹„íƒ€ë¯¼ ì´ë®¨í”ŒëŸ¬ìŠ¤ 14ë³‘ ìƒ· ë§ˆì‹œëŠ” ì•¡ìƒ ë¹„íƒ€ë¯¼ ì˜¬ì¸ì›<b>ì˜ì–‘ì œ</b> ì¢…ê·¼ë‹¹ ë„¤ì¶”ëŸ´ì›¨ì´ ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'link': 'https://smartstore.naver.com/main/products/11097440087',\n",
              "   'price': 21900,\n",
              "   'brand': 'ì¢…ê·¼ë‹¹',\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'imagelink': 'https://shopping-phinf.pstatic.net/main_8864195/88641950409.2.jpg'}},\n",
              " {'ì œí’ˆì •ë³´': 'ì•„ì´í•˜ì´ ì•„ì´ëª¨ì–´ 60ì • (1ë°•ìŠ¤)   ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'imagelink': 'https://shopping-phinf.pstatic.net/main_8910047/89100473463.jpg',\n",
              "   'price': 25700,\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'brand': '',\n",
              "   'link': 'https://smartstore.naver.com/main/products/11555963057'}},\n",
              " {'ì œí’ˆì •ë³´': 'ë² ë¡œì¹´ ë°œí¬ë¹„íƒ€ë¯¼ 60ì • ë©€í‹° ì¢…í•© ë¹„íƒ€ë¯¼ <b>ì˜ì–‘ì œ</b> ë¬¼ì—íƒ€ë¨¹ëŠ” ë§ˆì‹œëŠ” ì—ë„ˆì§€ ì½”ìŠ¤íŠ¸ì½” ë² ë¡œì¹´  ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'imagelink': 'https://shopping-phinf.pstatic.net/main_8671721/86717212249.3.jpg',\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'link': 'https://smartstore.naver.com/main/products/9172711926',\n",
              "   'brand': 'ë² ë¡œì¹´',\n",
              "   'price': 23700}},\n",
              " {'ì œí’ˆì •ë³´': 'ì–¼ë¼ì´ë¸Œ ì›ìŠ¤ë°ì¼ë¦¬ ë©€í‹°/í¬ë§¨/ ìš°ë¨¼ 60ì • ë¹„íƒ€ë¯¼Bêµ° ë¯¸ë„¤ë„ ì¢…í•©<b>ì˜ì–‘ì œ</b> ë„¤ì¸„ëŸ´ë¼ì´í”„ì–¼ë¼ì´ë¸Œ ë„¤ì´ì³ìŠ¤ì›¨ì´ ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'link': 'https://smartstore.naver.com/main/products/309612084',\n",
              "   'price': 23900,\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'brand': 'ë„¤ì¸„ëŸ´ë¼ì´í”„ì–¼ë¼ì´ë¸Œ',\n",
              "   'imagelink': 'https://shopping-phinf.pstatic.net/main_1009516/10095168405.11.jpg'}},\n",
              " {'ì œí’ˆì •ë³´': 'ì´ë®¨ ë©€í‹°ë¹„íƒ€ë¯¼ ì˜¬ì¸ì›<b>ì˜ì–‘ì œ</b> ì—¬ì„± ë‚¨ì„± ì¢…í•©ë¹„íƒ€ë¯¼ ë©€í‹°íŒ©   ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'brand': '',\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'imagelink': 'https://shopping-phinf.pstatic.net/main_8660229/86602293233.2.jpg',\n",
              "   'link': 'https://smartstore.naver.com/main/products/9057792910',\n",
              "   'price': 38800}},\n",
              " {'ì œí’ˆì •ë³´': 'ì–¼ë¼ì´ë¸Œ ì›ìŠ¤ë°ì¼ë¦¬ 100ì • ì¢…í•©ë¹„íƒ€ë¯¼ ë¯¸ë„¤ë„ ëŒ€ìš©ëŸ‰ ì½”ìŠ¤íŠ¸ì½”   ë¹„íƒ€ë¯¼ì œ ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "  'ë©”íƒ€ë°ì´í„°': {'imagelink': 'https://shopping-phinf.pstatic.net/main_8332262/83322625378.4.jpg',\n",
              "   'price': 24500,\n",
              "   'link': 'https://smartstore.naver.com/main/products/5778125964',\n",
              "   'category': 'ì‹í’ˆ>ê±´ê°•ì‹í’ˆ>ë¹„íƒ€ë¯¼ì œ>ë©€í‹°ë¹„íƒ€ë¯¼',\n",
              "   'brand': ''}}]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ê²€ìƒ‰ ë„êµ¬ í•¨ìˆ˜ ì •ì˜ (Function Calling)"
      ],
      "metadata": {
        "id": "G7eGjTt_AQg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "recommend_nutrient = {\n",
        "    \"name\": \"recommend_nutrient\",\n",
        "    \"description\": \"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìƒíƒœë¥¼ ë¶„ì„í•´ ì˜ì–‘ì†Œë¥¼ ì¶”ì²œí•©ë‹ˆë‹¤.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"nutrient\": {\"type\": \"string\", \"description\": \"ì¶”ì²œí•˜ëŠ” ì˜ì–‘ì†Œ ì„±ë¶„\"},\n",
        "            \"query\": {\"type\": \"string\", \"description\": \"ì‚¬ìš©ì ìƒíƒœ ì¿¼ë¦¬\"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"nutrient\", \"query\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "excessive_nutrient = {\n",
        "    \"name\": \"excessive_nutrient\",\n",
        "    \"description\": \"ì‚¬ìš©ìê°€ ì…ë ¥í•œ ì˜ì–‘ì œ ì„­ì·¨ ìƒíƒœë¥¼ ë¶„ì„í•´ ì¼ì¼ ê¶Œì¥ëŸ‰ì„ ì´ˆê³¼í•˜ëŠ” ì˜ì–‘ì†Œë¥¼ ì°¾ìŠµë‹ˆë‹¤.\",\n",
        "    \"parameters\": {\n",
        "        \"type\": \"object\",\n",
        "        \"properties\": {\n",
        "            \"nutrient\": {\"type\": \"string\", \"description\": \"ì´ˆê³¼í•˜ëŠ” ì˜ì–‘ì†Œ ì„±ë¶„\"},\n",
        "            \"query\": {\"type\": \"string\", \"description\": \"ê³„ì‚° ìˆ˜ì‹ê³¼ ì´ˆê³¼í•œ ì´ìœ \"\n",
        "            }\n",
        "        },\n",
        "        \"required\": [\"nutrient\", \"query\"]\n",
        "    }\n",
        "}\n",
        "\n",
        "vectordb_search_schema = {\n",
        "  \"name\": \"vectordb_search\",\n",
        "  \"description\": \"ì¶”ì²œ ì˜ì–‘ì†Œë¡œ Vector DBì—ì„œ ì œí’ˆ ê²€ìƒ‰\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"query\": {\"type\": \"string\"},\n",
        "      \"max_results\": {\"type\": \"integer\", \"default\": 10}\n",
        "    },\n",
        "    \"required\": [\"query\"]\n",
        "  }\n",
        "}\n",
        "\n",
        "google_search_function_schema = {\n",
        "  \"name\": \"google_search\",\n",
        "  \"description\": \"ê²€ìƒ‰ëœ ì œí’ˆì„ Google ê²€ìƒ‰í•´ì„œ ìƒì„¸ ì •ë³´ ì¡°íšŒ\",\n",
        "  \"parameters\": {\n",
        "    \"type\": \"object\",\n",
        "    \"properties\": {\n",
        "      \"query\": {\"type\": \"string\"},\n",
        "      \"num_results\": {\"type\": \"integer\", \"default\": 10}\n",
        "    },\n",
        "    \"required\": [\"query\"]\n",
        "  }\n",
        "}\n"
      ],
      "metadata": {
        "id": "Gr8ZOqz-_9bs"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LLM ë™ì‘ ì½”ë“œ"
      ],
      "metadata": {
        "id": "WBHbwmxxCTHy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "import json\n",
        "import re\n",
        "\n",
        "client = OpenAI(api_key=userdata.get('OPENAI_API_KEY'))\n",
        "\n",
        "def nutrient_too_much_check(symptom, gender, age, pregnancy, mode):\n",
        "    prompt = f\"\"\"\n",
        "    ì‚¬ìš©ì ì •ë³´:\n",
        "    - ì„±ë³„: {gender}\n",
        "    - ë‚˜ì´: {age}\n",
        "    - ì„ì‹  ì—¬ë¶€: {pregnancy}\n",
        "    - ì›í•˜ëŠ” ê²ƒ: {mode}\n",
        "    - ìƒíƒœ: {symptom}\n",
        "\n",
        "    í˜„ì¬ ì‚¬ìš©ìê°€ ì„­ì·¨í•˜ê³  ìˆëŠ” ìƒíƒœì¸ ê°ê° ì˜ì–‘ì†Œì˜ ì´ í•¨ëŸ‰ê³¼ í•´ë‹¹ ì˜ì–‘ì†Œì˜ ì¼ì¼ ê¶Œì¥ëŸ‰ì„ ë¹„êµí•˜ì—¬ ì´ˆê³¼/ë¯¸ë‹¬ ì—¬ë¶€ë¥¼ ê³„ì‚°í•˜ì„¸ìš”. ê³„ì‚° ê·¼ê±°ë¥¼ ê°™ì´ ì œì‹œí•˜ì„¸ìš”.\n",
        "    \"\"\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"ë„ˆëŠ” ê±´ê°• ê¸°ë°˜ì˜ ì˜ì–‘ì œ ì¡°ì–¸ ì „ë¬¸ê°€ì•¼. ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    print(\"í˜„ì¬ messages:\", messages)\n",
        "\n",
        "    res = client.chat.completions.create(\n",
        "        model=gpt_target,\n",
        "        messages=messages,\n",
        "        functions=[excessive_nutrient],\n",
        "        function_call={\"name\": \"excessive_nutrient\"},\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    func_name = res.choices[0].message.function_call.name\n",
        "    print(\"í˜¸ì¶œëœ í•¨ìˆ˜:\", func_name)\n",
        "    print(\"í•¨ìˆ˜ ì¸ì(raw):\", res.choices[0].message.function_call.arguments)\n",
        "\n",
        "    args = json.loads(res.choices[0].message.function_call.arguments)\n",
        "    print(args)\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": None,\n",
        "        \"function_call\": {\n",
        "            \"name\": func_name,\n",
        "            \"arguments\": res.choices[0].message.function_call.arguments\n",
        "        }\n",
        "    })\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"function\",\n",
        "        \"name\": func_name,\n",
        "        \"content\": f\"ê³¼ë‹¤ ë³µìš© ë¶„ì„ ê²°ê³¼: {json.dumps(args, ensure_ascii=False)}\"\n",
        "    })\n",
        "\n",
        "    # ìµœì¢… ì‘ë‹µ í¬ë§·: ì„±ë¶„ ì¤‘ì‹¬ ì¹´ë“œ í˜•íƒœ\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"\n",
        "ê° ì„±ë¶„ë³„ë¡œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ì •ë¦¬í•´ì£¼ì„¸ìš”:\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ ì„±ë¶„ëª…     â”‚ [ì˜ˆ: ë¹„íƒ€ë¯¼ D]\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ì„­ì·¨ëŸ‰     â”‚ [ìˆ«ì ë° ë‹¨ìœ„]\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ê¶Œì¥ëŸ‰     â”‚ [ìˆ«ì ë° ë‹¨ìœ„]\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ì´ˆê³¼ëŸ‰     â”‚ [Â±ìˆ«ì ë° ë‹¨ìœ„]\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ì´ˆê³¼ ì—¬ë¶€  â”‚ âœ… ì´ˆê³¼ ì„­ì·¨ / âŒ ë¯¸ë‹¬ ì„­ì·¨\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "ğŸ›¡ï¸ AI Agentì˜ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤.\n",
        "ë³µìš© ì¤‘ì¸ ì•½ë¬¼ì´ë‚˜ ì§€ë³‘ì´ ìˆë‹¤ë©´ ë°˜ë“œì‹œ ì „ë¬¸ê°€ì™€ ìƒë‹´í•˜ì„¸ìš”.\n",
        "        \"\"\"\n",
        "    })\n",
        "\n",
        "    final_response = client.chat.completions.create(\n",
        "        model=gpt_target,\n",
        "        messages=messages,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    print(\"\\nìµœì¢… ê²°ê³¼:\")\n",
        "    print(final_response.choices[0].message.content)\n",
        "\n",
        "\n",
        "def nutrient_recommend_check(symptom, gender, age, pregnancy, mode):\n",
        "    prompt = f\"\"\"\n",
        "    ì‚¬ìš©ì ì •ë³´:\n",
        "    - ì„±ë³„: {gender}\n",
        "    - ë‚˜ì´: {age}\n",
        "    - ì„ì‹  ì—¬ë¶€: {pregnancy}\n",
        "    - ì›í•˜ëŠ” ê²ƒ: {mode}\n",
        "    - ìƒíƒœ: {symptom}\n",
        "    \"\"\"\n",
        "\n",
        "    if mode == \"ì‹ìŠµê´€ ë¶„ì„ì„ í†µí•œ ì˜ì–‘ì œ ì¶”ì²œ\":\n",
        "        prompt += \"\\ní˜„ì¬ ì‚¬ìš©ìì˜ ì‹ì‚¬ ìŠµê´€ ìƒíƒœë¥¼ ê³ ë ¤í•˜ì—¬ ê²°í•ë˜ê±°ë‚˜ ë³´ì¡°ì ìœ¼ë¡œ ì„­ì·¨ê°€ í•„ìš”í•œ ê°€ì¥ ì ì ˆí•œ ì˜ì–‘ì†Œë¥¼ 2ê°€ì§€ ì¶”ì²œí•˜ì„¸ìš”.\\n\"\n",
        "    elif mode == \"ë¶ˆí¸ í˜„ìƒì— ë”°ë¥¸ ì˜ì–‘ì œ ì¶”ì²œ\":\n",
        "        prompt += \"\\ní˜„ì¬ ì‚¬ìš©ìê°€ ë¶ˆí¸í•´ í•˜ëŠ” ìƒíƒœë¥¼ í•´ê²°í•  ìˆ˜ ìˆëŠ” ê°€ì¥ ì ì ˆí•œ ì˜ì–‘ì†Œë¥¼ 2ê°€ì§€ ì¶”ì²œí•˜ì„¸ìš”.\\n\"\n",
        "\n",
        "    nutrient_recommend(prompt, symptom, gender, age, pregnancy, mode)\n",
        "\n",
        "\n",
        "def nutrient_recommend(condition, symptom, gender, age, pregnancy, mode):\n",
        "    prompt = condition\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"system\",\n",
        "            \"content\": \"ë„ˆëŠ” ê±´ê°• ê¸°ë°˜ì˜ ì˜ì–‘ì œ ì¡°ì–¸ ì „ë¬¸ê°€ì•¼. ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì¤˜.\"\n",
        "        },\n",
        "        {\"role\": \"user\", \"content\": prompt}\n",
        "    ]\n",
        "\n",
        "    print(\"í˜„ì¬ messages:\", messages)\n",
        "\n",
        "    res = client.chat.completions.create(\n",
        "        model=gpt_target,\n",
        "        messages=messages,\n",
        "        functions=[recommend_nutrient],\n",
        "        function_call={\"name\": \"recommend_nutrient\"},\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    func_name = res.choices[0].message.function_call.name\n",
        "    print(\"í˜¸ì¶œëœ í•¨ìˆ˜:\", func_name)\n",
        "    print(\"í•¨ìˆ˜ ì¸ì(raw):\", res.choices[0].message.function_call.arguments)\n",
        "\n",
        "    args = json.loads(res.choices[0].message.function_call.arguments)\n",
        "    nutrient = args[\"nutrient\"]\n",
        "    print(f\"ì¶”ì²œ ì˜ì–‘ì†Œ: {nutrient}\")\n",
        "\n",
        "    # Step 2: VectorDB ê²€ìƒ‰\n",
        "    search_results = vectordb_search(args[\"query\"])\n",
        "    messages.append({\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": None,\n",
        "        \"function_call\": {\n",
        "            \"name\": func_name,\n",
        "            \"arguments\": res.choices[0].message.function_call.arguments\n",
        "        }\n",
        "    })\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"function\",\n",
        "        \"name\": func_name,\n",
        "        \"content\": f\"VectorDB ê²€ìƒ‰ ê²°ê³¼: {json.dumps(search_results)}\"\n",
        "    })\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"Vector DBì—ì„œ ê²€ìƒ‰í•œ ì¶”ì²œí•˜ëŠ” ì˜ì–‘ì†Œë¥¼ í¬í•¨í•˜ëŠ” ì˜ì–‘ì œ ì œí’ˆ ì¤‘ ì œì¼ ì í•©í•œ ì˜ì–‘ì œ ì œí’ˆ 2ê°œë¥¼ ì°¾ìœ¼ì„¸ìš”\"\n",
        "    })\n",
        "\n",
        "    res = client.chat.completions.create(\n",
        "        model=gpt_target,\n",
        "        messages=messages,\n",
        "        functions=[vectordb_search_schema],\n",
        "        function_call={\"name\": \"vectordb_search\"},\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    func_name = res.choices[0].message.function_call.name\n",
        "    print(\"í˜¸ì¶œëœ í•¨ìˆ˜:\", func_name)\n",
        "    print(\"í•¨ìˆ˜ ì¸ì(raw):\", res.choices[0].message.function_call.arguments)\n",
        "    print(\"ë©”ì„¸ì§€: \", res.choices[0].message)\n",
        "\n",
        "    # Step 3: Google ê²€ìƒ‰\n",
        "    args = json.loads(res.choices[0].message.function_call.arguments)\n",
        "    search_results = google_search(args[\"query\"])\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"assistant\",\n",
        "        \"content\": None,\n",
        "        \"function_call\": {\n",
        "            \"name\": func_name,\n",
        "            \"arguments\": res.choices[0].message.function_call.arguments\n",
        "        }\n",
        "    })\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"function\",\n",
        "        \"name\": func_name,\n",
        "        \"content\": f\"Google ê²€ìƒ‰ ê²°ê³¼: {json.dumps(search_results)}\"\n",
        "    })\n",
        "\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"ì°¾ì€ ì˜ì–‘ì œ ì œí’ˆì„ Googleì—ì„œ ê²€ìƒ‰í•˜ì—¬ ìì„¸í•œ í•¨ëŸ‰ ì •ë³´ë¥¼ ìˆ˜ì§‘í•˜ì„¸ìš”.\"\n",
        "    })\n",
        "\n",
        "    res = client.chat.completions.create(\n",
        "        model=gpt_target,\n",
        "        messages=messages,\n",
        "        functions=[google_search_function_schema],\n",
        "        function_call={\"name\": \"google_search\"},\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    func_name = res.choices[0].message.function_call.name\n",
        "    print(\"í˜¸ì¶œëœ í•¨ìˆ˜:\", func_name)\n",
        "    print(\"í•¨ìˆ˜ ì¸ì(raw):\", res.choices[0].message.function_call.arguments)\n",
        "    print(\"ë©”ì„¸ì§€: \", res.choices[0].message)\n",
        "\n",
        "    # ìµœì¢… ì‘ë‹µ í¬ë§·: ì œí’ˆ ì •ë³´ ì¹´ë“œ í˜•íƒœ\n",
        "    messages.append({\n",
        "        \"role\": \"user\",\n",
        "        \"content\": \"\"\"\n",
        "ì§€ê¸ˆê¹Œì§€ì˜ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì¢…í•©í•´ì„œ ì•„ë˜ í˜•ì‹ìœ¼ë¡œ ë³´ê¸° ì¢‹ê²Œ ì •ë¦¬í•´ì£¼ì„¸ìš”.\n",
        "\n",
        "â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”\n",
        "â”‚ ì œì¡°ì‚¬     â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ì œí’ˆëª…     â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ì£¼ìš” ì„±ë¶„  â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ í•¨ëŸ‰       â”‚\n",
        "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
        "â”‚ ë§í¬       â”‚\n",
        "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
        "\n",
        "ì‚¬ìš©ìì˜ ì•ˆì „ì„ ìœ„í•´ ë‹¤ìŒ ë¬¸êµ¬ë¥¼ ë§ˆì§€ë§‰ì— ì¶”ê°€í•˜ì„¸ìš”:\n",
        "'AI Agentê°€ ì¡°ì–¸í•˜ëŠ” ë‚´ìš©ì…ë‹ˆë‹¤. ê±´ê°•ì— ì´ìƒì´ ìˆê±°ë‚˜ ë³µìš© ì¤‘ì¸ ì•½ë¬¼ì´ ìˆë‹¤ë©´ ì „ë¬¸ê°€ ìƒë‹´ì„ ë°›ìœ¼ì„¸ìš”.'\n",
        "        \"\"\"\n",
        "    })\n",
        "\n",
        "    final_response = client.chat.completions.create(\n",
        "        model=gpt_target,\n",
        "        messages=messages,\n",
        "        temperature=0.5\n",
        "    )\n",
        "\n",
        "    print(\"\\nìµœì¢… ê²°ê³¼:\")\n",
        "    print(final_response.choices[0].message.content)\n",
        "\n",
        "\n",
        "def llm_divider(symptom, gender, age, pregnancy, mode):\n",
        "    if mode in [\"ì‹ìŠµê´€ ë¶„ì„ì„ í†µí•œ ì˜ì–‘ì œ ì¶”ì²œ\", \"ë¶ˆí¸ í˜„ìƒì— ë”°ë¥¸ ì˜ì–‘ì œ ì¶”ì²œ\"]:\n",
        "        nutrient_recommend_check(symptom, gender, age, pregnancy, mode)\n",
        "    elif mode == \"ì˜ì–‘ì œ ê³¼ë‹¤ ë³µìš© í™•ì¸\":\n",
        "        nutrient_too_much_check(symptom, gender, age, pregnancy, mode)\n"
      ],
      "metadata": {
        "id": "nHAUUZQKCQ8r"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# User Interface ì‹¤í–‰"
      ],
      "metadata": {
        "id": "NZ8lMnlmDH1E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "import io\n",
        "import sys\n",
        "\n",
        "def nutrient_advisor(symptom, gender, age, pregnancy, mode):\n",
        "    old_stdout = sys.stdout\n",
        "    sys.stdout = mystdout = io.StringIO()\n",
        "    llm_divider(symptom, gender, age, pregnancy, mode)\n",
        "    sys.stdout = old_stdout\n",
        "    return mystdout.getvalue()\n",
        "\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"# ì˜ì–‘ì œ ì¶”ì²œ/ê³¼ë‹¤ ë³µìš© í™•ì¸\")\n",
        "    gender = gr.Radio([\"ë‚¨ì„±\", \"ì—¬ì„±\"], label=\"ì„±ë³„\")\n",
        "    age = gr.Number(value=30, label=\"ë§Œ ë‚˜ì´\")\n",
        "    pregnancy = gr.Radio([\"í•´ë‹¹ ì—†ìŒ\", \"ì„ì‹  ì¤‘\", \"ì„ì‹  ê°€ëŠ¥ì„±\"], label=\"ì„ì‹  ì—¬ë¶€\")\n",
        "    mode = gr.Radio(\n",
        "        [\"ì‹ìŠµê´€ ë¶„ì„ì„ í†µí•œ ì˜ì–‘ì œ ì¶”ì²œ\", \"ë¶ˆí¸ í˜„ìƒì— ë”°ë¥¸ ì˜ì–‘ì œ ì¶”ì²œ\", \"ì˜ì–‘ì œ ê³¼ë‹¤ ë³µìš© í™•ì¸\"],\n",
        "        label=\"ë©”ë‰´\"\n",
        "    )\n",
        "    symptom = gr.Textbox(label=\"ì¦ìƒ ë˜ëŠ” ë³µìš© ì œí’ˆ ì…ë ¥\", placeholder=\"ì¦ìƒ ë˜ëŠ” ë³µìš© ì œí’ˆ ì…ë ¥\")\n",
        "    submit = gr.Button(\"ì œì¶œ\")\n",
        "    output = gr.Textbox(label=\"ê²°ê³¼\", lines=15)\n",
        "\n",
        "    submit.click(\n",
        "        nutrient_advisor,\n",
        "        inputs=[symptom, gender, age, pregnancy, mode],\n",
        "        outputs=output\n",
        "    )\n",
        "\n",
        "demo.launch(share=True, debug=False)\n"
      ],
      "metadata": {
        "id": "9TwC_bL4umPS",
        "outputId": "60d8bea3-763b-4f0c-e428-ebdbf085b5d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 520
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://cf278972f28a47dca2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}